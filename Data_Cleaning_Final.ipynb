{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XYWi_uNXAT8l"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "5RMTErCnCGM2",
    "outputId": "8efff3f2-201d-40cc-e0b3-dead6bec53d6"
   },
   "outputs": [],
   "source": [
    "#Reading csv files\n",
    "orders = pd.read_csv('olist_orders_dataset.csv')\n",
    "order_items = pd.read_csv('olist_order_items_dataset.csv')\n",
    "customers = pd.read_csv('olist_customers_dataset.csv')\n",
    "sellers = pd.read_csv('olist_sellers_dataset.csv')\n",
    "geolocation = pd.read_csv('olist_geolocation_dataset.csv')\n",
    "products = pd.read_csv('olist_products_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 8 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   order_id                       99441 non-null  object\n",
      " 1   customer_id                    99441 non-null  object\n",
      " 2   order_status                   99441 non-null  object\n",
      " 3   order_purchase_timestamp       99441 non-null  object\n",
      " 4   order_approved_at              99281 non-null  object\n",
      " 5   order_delivered_carrier_date   97658 non-null  object\n",
      " 6   order_delivered_customer_date  96476 non-null  object\n",
      " 7   order_estimated_delivery_date  99441 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "orders.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99441\n"
     ]
    }
   ],
   "source": [
    "# before filtering\n",
    "original_order = orders.shape[0]\n",
    "print(original_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique order statuses after filtering: ['delivered']\n"
     ]
    }
   ],
   "source": [
    "# Filter for orders with 'order_status' as 'delivered'\n",
    "orders = orders[orders['order_status'] == 'delivered']\n",
    "\n",
    "# Confirm the filter worked by checking unique values in 'order_status'\n",
    "print(\"Unique order statuses after filtering:\", orders['order_status'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96478\n"
     ]
    }
   ],
   "source": [
    "# After filtering delivered status\n",
    "delivered_order = orders.shape[0]\n",
    "print(delivered_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2963\n"
     ]
    }
   ],
   "source": [
    "# We want to know how many data were dropped after filtering\n",
    "data_drop = original_order - delivered_order\n",
    "print(data_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate entries in order table:\n",
      " Empty DataFrame\n",
      "Columns: [order_id, customer_id, order_status, order_purchase_timestamp, order_approved_at, order_delivered_carrier_date, order_delivered_customer_date, order_estimated_delivery_date]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in order table\n",
    "duplicate_order_id = orders[orders.duplicated(subset='order_id')]\n",
    "print(\"Duplicate entries in order table:\\n\", duplicate_order_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime\n",
    "orders['order_purchase_timestamp'] = pd.to_datetime(orders['order_purchase_timestamp'])\n",
    "orders['order_delivered_customer_date'] = pd.to_datetime(orders['order_delivered_customer_date'])\n",
    "orders['order_estimated_delivery_date'] = pd.to_datetime(orders['order_estimated_delivery_date'])\n",
    "orders['order_approved_at'] = pd.to_datetime(orders['order_approved_at'])\n",
    "orders['order_delivered_carrier_date'] = pd.to_datetime(orders['order_delivered_carrier_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of delay variable: delay\n",
      "0    88652\n",
      "1     7826\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create target variable 'delay': 1 if delayed, 0 if on-time\n",
    "orders['delay'] = (orders['order_delivered_customer_date'] > orders['order_estimated_delivery_date']).astype(int)\n",
    "\n",
    "# Check distribution of target variable\n",
    "print(\"Distribution of delay variable:\", orders['delay'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 5 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   customer_id               99441 non-null  object\n",
      " 1   customer_unique_id        99441 non-null  object\n",
      " 2   customer_zip_code_prefix  99441 non-null  int64 \n",
      " 3   customer_city             99441 non-null  object\n",
      " 4   customer_state            99441 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "customers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns\n",
    "customers = customers[['customer_id', 'customer_zip_code_prefix']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate entries in customers table:\n",
      " Empty DataFrame\n",
      "Columns: [customer_id, customer_zip_code_prefix]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in customers\n",
    "duplicate_customers = customers[customers.duplicated(subset='customer_id')]\n",
    "print(\"Duplicate entries in customers table:\\n\", duplicate_customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sellers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3095 entries, 0 to 3094\n",
      "Data columns (total 4 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   seller_id               3095 non-null   object\n",
      " 1   seller_zip_code_prefix  3095 non-null   int64 \n",
      " 2   seller_city             3095 non-null   object\n",
      " 3   seller_state            3095 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 96.8+ KB\n"
     ]
    }
   ],
   "source": [
    "sellers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns\n",
    "sellers = sellers[['seller_id', 'seller_zip_code_prefix']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate entries in sellers table:\n",
      " Empty DataFrame\n",
      "Columns: [seller_id, seller_zip_code_prefix]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in sellers\n",
    "duplicate_sellers = sellers[sellers.duplicated(subset='seller_id')]\n",
    "print(\"Duplicate entries in sellers table:\\n\", duplicate_sellers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32951 entries, 0 to 32950\n",
      "Data columns (total 9 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   product_id                  32951 non-null  object \n",
      " 1   product_category_name       32341 non-null  object \n",
      " 2   product_name_lenght         32341 non-null  float64\n",
      " 3   product_description_lenght  32341 non-null  float64\n",
      " 4   product_photos_qty          32341 non-null  float64\n",
      " 5   product_weight_g            32949 non-null  float64\n",
      " 6   product_length_cm           32949 non-null  float64\n",
      " 7   product_height_cm           32949 non-null  float64\n",
      " 8   product_width_cm            32949 non-null  float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "products.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns\n",
    "products = products[['product_id', 'product_weight_g', 'product_length_cm', 'product_height_cm', 'product_width_cm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate entries in products table:\n",
      " Empty DataFrame\n",
      "Columns: [product_id, product_weight_g, product_length_cm, product_height_cm, product_width_cm]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in products\n",
    "duplicate_products = products[products.duplicated(subset='product_id')]\n",
    "print(\"Duplicate entries in products table:\\n\", duplicate_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geolocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000163 entries, 0 to 1000162\n",
      "Data columns (total 5 columns):\n",
      " #   Column                       Non-Null Count    Dtype  \n",
      "---  ------                       --------------    -----  \n",
      " 0   geolocation_zip_code_prefix  1000163 non-null  int64  \n",
      " 1   geolocation_lat              1000163 non-null  float64\n",
      " 2   geolocation_lng              1000163 non-null  float64\n",
      " 3   geolocation_city             1000163 non-null  object \n",
      " 4   geolocation_state            1000163 non-null  object \n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 38.2+ MB\n"
     ]
    }
   ],
   "source": [
    "geolocation.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate entries in geolocation table:\n",
      "          geolocation_zip_code_prefix  geolocation_lat  geolocation_lng  \\\n",
      "2                               1046       -23.546129       -46.642951   \n",
      "10                              1013       -23.547325       -46.634184   \n",
      "13                              1012       -23.548946       -46.634671   \n",
      "14                              1037       -23.545187       -46.637855   \n",
      "15                              1046       -23.546081       -46.644820   \n",
      "...                              ...              ...              ...   \n",
      "1000158                        99950       -28.068639       -52.010705   \n",
      "1000159                        99900       -27.877125       -52.224882   \n",
      "1000160                        99950       -28.071855       -52.014716   \n",
      "1000161                        99980       -28.388932       -51.846871   \n",
      "1000162                        99950       -28.070104       -52.018658   \n",
      "\n",
      "        geolocation_city geolocation_state  \n",
      "2              sao paulo                SP  \n",
      "10             sao paulo                SP  \n",
      "13             sao paulo                SP  \n",
      "14             são paulo                SP  \n",
      "15             sao paulo                SP  \n",
      "...                  ...               ...  \n",
      "1000158         tapejara                RS  \n",
      "1000159   getulio vargas                RS  \n",
      "1000160         tapejara                RS  \n",
      "1000161  david canabarro                RS  \n",
      "1000162         tapejara                RS  \n",
      "\n",
      "[981148 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in geolocation\n",
    "duplicate_geolocation = geolocation[geolocation.duplicated(subset='geolocation_zip_code_prefix')]\n",
    "print(\"Duplicate entries in geolocation table:\\n\", duplicate_geolocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000163\n"
     ]
    }
   ],
   "source": [
    "# number of rows before removing duplicates\n",
    "original_geolocation = geolocation.shape[0]\n",
    "print(original_geolocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geolocation Dataset Cleaned:\n",
      "    geolocation_zip_code_prefix  geolocation_lat  geolocation_lng  \\\n",
      "0                         1037       -23.545621       -46.639292   \n",
      "1                         1046       -23.546081       -46.644820   \n",
      "3                         1041       -23.544392       -46.639499   \n",
      "4                         1035       -23.541578       -46.641607   \n",
      "5                         1012       -23.547762       -46.635361   \n",
      "\n",
      "  geolocation_city geolocation_state  \n",
      "0        sao paulo                SP  \n",
      "1        sao paulo                SP  \n",
      "3        sao paulo                SP  \n",
      "4        sao paulo                SP  \n",
      "5        são paulo                SP  \n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "geolocation = geolocation.drop_duplicates(subset='geolocation_zip_code_prefix')\n",
    "\n",
    "# Check cleaned data\n",
    "print(\"Geolocation Dataset Cleaned:\\n\", geolocation.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19015\n"
     ]
    }
   ],
   "source": [
    "# number of unique rows in geolocation after removing duplicates\n",
    "unique_geolocation = geolocation.shape[0]\n",
    "print(unique_geolocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981148\n"
     ]
    }
   ],
   "source": [
    "# number of rows dropped after removing duplicates\n",
    "dropped_rows = original_geolocation - unique_geolocation\n",
    "print(dropped_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### order_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112650 entries, 0 to 112649\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   order_id             112650 non-null  object \n",
      " 1   order_item_id        112650 non-null  int64  \n",
      " 2   product_id           112650 non-null  object \n",
      " 3   seller_id            112650 non-null  object \n",
      " 4   shipping_limit_date  112650 non-null  object \n",
      " 5   price                112650 non-null  float64\n",
      " 6   freight_value        112650 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "order_items.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns\n",
    "order_items = order_items[['order_id', 'order_item_id', 'product_id', 'seller_id', 'shipping_limit_date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime\n",
    "order_items['shipping_limit_date'] = pd.to_datetime(order_items['shipping_limit_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate entries in order item table:\n",
      "                                 order_id  order_item_id  \\\n",
      "14      0008288aa423d2a3f00fcb17cd7d8719              2   \n",
      "33      00143d0f86d6fbd9f9b38ab440ac16f5              2   \n",
      "34      00143d0f86d6fbd9f9b38ab440ac16f5              3   \n",
      "43      001ab0a7578dd66cd4b0a71f5b6e1e41              2   \n",
      "44      001ab0a7578dd66cd4b0a71f5b6e1e41              3   \n",
      "...                                  ...            ...   \n",
      "112617  ffecd5a79a0084f6a592288c67e3c298              3   \n",
      "112635  fff8287bbae429a99bb7e8c21d151c41              2   \n",
      "112641  fffb9224b6fc7c43ebb0904318b10b5f              2   \n",
      "112642  fffb9224b6fc7c43ebb0904318b10b5f              3   \n",
      "112643  fffb9224b6fc7c43ebb0904318b10b5f              4   \n",
      "\n",
      "                              product_id                         seller_id  \\\n",
      "14      368c6c730842d78016ad823897a372db  1f50f920176fa81dab994f9023523100   \n",
      "33      e95ee6822b66ac6058e2e4aff656071a  a17f621c590ea0fab3d5d883e1630ec6   \n",
      "34      e95ee6822b66ac6058e2e4aff656071a  a17f621c590ea0fab3d5d883e1630ec6   \n",
      "43      0b0172eb0fd18479d29c3bc122c058c2  5656537e588803a555b8eb41f07a944b   \n",
      "44      0b0172eb0fd18479d29c3bc122c058c2  5656537e588803a555b8eb41f07a944b   \n",
      "...                                  ...                               ...   \n",
      "112617  50fd2b788dc166edd20512370dac54df  8b321bb669392f5163d04c59e235e066   \n",
      "112635  bee2e070c39f3dd2f6883a17a5f0da45  4e922959ae960d389249c378d1c939f5   \n",
      "112641  43423cdffde7fda63d0414ed38c11a73  b1fc4f64df5a0e8b6913ab38803c57a9   \n",
      "112642  43423cdffde7fda63d0414ed38c11a73  b1fc4f64df5a0e8b6913ab38803c57a9   \n",
      "112643  43423cdffde7fda63d0414ed38c11a73  b1fc4f64df5a0e8b6913ab38803c57a9   \n",
      "\n",
      "       shipping_limit_date  \n",
      "14     2018-02-21 02:55:52  \n",
      "33     2017-10-20 16:07:52  \n",
      "34     2017-10-20 16:07:52  \n",
      "43     2018-01-04 02:33:42  \n",
      "44     2018-01-04 02:33:42  \n",
      "...                    ...  \n",
      "112617 2018-03-05 20:15:27  \n",
      "112635 2018-03-27 12:29:22  \n",
      "112641 2017-11-03 02:55:58  \n",
      "112642 2017-11-03 02:55:58  \n",
      "112643 2017-11-03 02:55:58  \n",
      "\n",
      "[13984 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in order item table\n",
    "duplicate_order_item_id = order_items[order_items.duplicated(subset='order_id')]\n",
    "print(\"Duplicate entries in order item table:\\n\", duplicate_order_item_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique order_id: 98666\n"
     ]
    }
   ],
   "source": [
    "# Count unique order_id\n",
    "unique_order_ids_count = order_items['order_id'].nunique()\n",
    "print(f\"Number of unique order_id: {unique_order_ids_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of orders with multiple products: 3236\n",
      "order_id\n",
      "002f98c0f7efd42638ed6100ca699b42    2\n",
      "00337fe25a3780b3424d9ad7c5a4b35e    2\n",
      "005d9a5423d47281ac463a968b3936fb    2\n",
      "00946f674d880be1f188abc10ad7cf46    2\n",
      "0097f0545a302aafa32782f1734ff71c    2\n",
      "Name: product_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of unique product_id per order_id\n",
    "multiple_products = order_items.groupby('order_id')['product_id'].nunique()\n",
    "\n",
    "# Filter orders with more than one product\n",
    "multiple_products = multiple_products[multiple_products > 1]\n",
    "\n",
    "# Display the results\n",
    "print(f\"Number of orders with multiple products: {multiple_products.shape[0]}\")\n",
    "print(multiple_products.head())  # Display first few entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of orders with multiple sellers: 1278\n",
      "order_id\n",
      "002f98c0f7efd42638ed6100ca699b42    2\n",
      "00bcee890eba57a9767c7b5ca12d3a1b    2\n",
      "01144cadcf64b6427f0a6580a3033220    2\n",
      "013a98b3a668bcef05b98898177f6923    2\n",
      "014405982914c2cde2796ddcf0b8703d    2\n",
      "Name: seller_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of unique seller_id per order_id\n",
    "multiple_sellers = order_items.groupby('order_id')['seller_id'].nunique()\n",
    "\n",
    "# Filter orders with more than one seller\n",
    "multiple_sellers = multiple_sellers[multiple_sellers > 1]\n",
    "\n",
    "# Display the results\n",
    "print(f\"Number of orders with multiple sellers: {multiple_sellers.shape[0]}\")\n",
    "print(multiple_sellers.head())  # Display first few entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KOp9ybVVNCuF",
    "outputId": "2213446c-fc7c-4500-f09f-4a5f2c35e8a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Data Structure:\n",
      "                            order_id                       customer_id  \\\n",
      "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
      "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
      "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
      "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
      "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
      "\n",
      "  order_status order_purchase_timestamp   order_approved_at  \\\n",
      "0    delivered      2017-10-02 10:56:33 2017-10-02 11:07:15   \n",
      "1    delivered      2018-07-24 20:41:37 2018-07-26 03:24:27   \n",
      "2    delivered      2018-08-08 08:38:49 2018-08-08 08:55:23   \n",
      "3    delivered      2017-11-18 19:28:06 2017-11-18 19:45:59   \n",
      "4    delivered      2018-02-13 21:18:39 2018-02-13 22:20:29   \n",
      "\n",
      "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
      "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
      "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
      "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
      "3          2017-11-22 13:39:59           2017-12-02 00:28:42   \n",
      "4          2018-02-14 19:46:34           2018-02-16 18:17:02   \n",
      "\n",
      "  order_estimated_delivery_date  delay  order_item_id  ...  \\\n",
      "0                    2017-10-18      0              1  ...   \n",
      "1                    2018-08-13      0              1  ...   \n",
      "2                    2018-09-04      0              1  ...   \n",
      "3                    2017-12-15      0              1  ...   \n",
      "4                    2018-02-26      0              1  ...   \n",
      "\n",
      "  geolocation_state_customer geolocation_zip_code_prefix_seller  \\\n",
      "0                         SP                             9350.0   \n",
      "1                         BA                            31570.0   \n",
      "2                         GO                            14840.0   \n",
      "3                         RN                            31842.0   \n",
      "4                         SP                             8752.0   \n",
      "\n",
      "  geolocation_lat_seller  geolocation_lng_seller  geolocation_city_seller  \\\n",
      "0             -23.680114              -46.452454                     maua   \n",
      "1             -19.810119              -43.984727           belo horizonte   \n",
      "2             -21.362358              -48.232976                  guariba   \n",
      "3             -19.840168              -43.923299           belo horizonte   \n",
      "4             -23.551707              -46.260979          mogi das cruzes   \n",
      "\n",
      "   geolocation_state_seller  product_weight_g  product_length_cm  \\\n",
      "0                        SP             500.0               19.0   \n",
      "1                        MG             400.0               19.0   \n",
      "2                        SP             420.0               24.0   \n",
      "3                        MG             450.0               30.0   \n",
      "4                        SP             250.0               51.0   \n",
      "\n",
      "  product_height_cm product_width_cm  \n",
      "0               8.0             13.0  \n",
      "1              13.0             19.0  \n",
      "2              19.0             21.0  \n",
      "3              10.0             20.0  \n",
      "4              15.0             15.0  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge orders with order_items on 'order_id'\n",
    "data = pd.merge(orders, order_items, on='order_id', how='inner')\n",
    "\n",
    "# Merge with customers on 'customer_id'\n",
    "data = pd.merge(data, customers, on='customer_id', how='inner')\n",
    "\n",
    "# Merge with sellers on 'seller_id'\n",
    "data = pd.merge(data, sellers, on='seller_id', how='inner')\n",
    "\n",
    "# Add geolocation data for customers and sellers\n",
    "data = pd.merge(data, geolocation, left_on='customer_zip_code_prefix',\n",
    "                right_on='geolocation_zip_code_prefix', how='left', suffixes=('_customer', '_seller'))\n",
    "\n",
    "data = pd.merge(data, geolocation, left_on='seller_zip_code_prefix',\n",
    "                right_on='geolocation_zip_code_prefix', how='left', suffixes=('_customer', '_seller'))\n",
    "\n",
    "# Merge with products on 'product_id'\n",
    "data = pd.merge(data, products, on='product_id', how='inner')\n",
    "\n",
    "# Check merged data structure\n",
    "print(\"Merged Data Structure:\\n\", data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110197\n"
     ]
    }
   ],
   "source": [
    "# before dropping null values in merged dataset\n",
    "original_data = data.shape[0]\n",
    "print(original_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "eE0iXXh9MFHm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in merged dataset:\n",
      " order_id                                  0\n",
      "customer_id                               0\n",
      "order_status                              0\n",
      "order_purchase_timestamp                  0\n",
      "order_approved_at                        15\n",
      "order_delivered_carrier_date              2\n",
      "order_delivered_customer_date             8\n",
      "order_estimated_delivery_date             0\n",
      "delay                                     0\n",
      "order_item_id                             0\n",
      "product_id                                0\n",
      "seller_id                                 0\n",
      "shipping_limit_date                       0\n",
      "customer_zip_code_prefix                  0\n",
      "seller_zip_code_prefix                    0\n",
      "geolocation_zip_code_prefix_customer    288\n",
      "geolocation_lat_customer                288\n",
      "geolocation_lng_customer                288\n",
      "geolocation_city_customer               288\n",
      "geolocation_state_customer              288\n",
      "geolocation_zip_code_prefix_seller      249\n",
      "geolocation_lat_seller                  249\n",
      "geolocation_lng_seller                  249\n",
      "geolocation_city_seller                 249\n",
      "geolocation_state_seller                249\n",
      "product_weight_g                         18\n",
      "product_length_cm                        18\n",
      "product_height_cm                        18\n",
      "product_width_cm                         18\n",
      "dtype: int64\n",
      "Null values after final drop:\n",
      " order_id                                0\n",
      "customer_id                             0\n",
      "order_status                            0\n",
      "order_purchase_timestamp                0\n",
      "order_approved_at                       0\n",
      "order_delivered_carrier_date            0\n",
      "order_delivered_customer_date           0\n",
      "order_estimated_delivery_date           0\n",
      "delay                                   0\n",
      "order_item_id                           0\n",
      "product_id                              0\n",
      "seller_id                               0\n",
      "shipping_limit_date                     0\n",
      "customer_zip_code_prefix                0\n",
      "seller_zip_code_prefix                  0\n",
      "geolocation_zip_code_prefix_customer    0\n",
      "geolocation_lat_customer                0\n",
      "geolocation_lng_customer                0\n",
      "geolocation_city_customer               0\n",
      "geolocation_state_customer              0\n",
      "geolocation_zip_code_prefix_seller      0\n",
      "geolocation_lat_seller                  0\n",
      "geolocation_lng_seller                  0\n",
      "geolocation_city_seller                 0\n",
      "geolocation_state_seller                0\n",
      "product_weight_g                        0\n",
      "product_length_cm                       0\n",
      "product_height_cm                       0\n",
      "product_width_cm                        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for remaining null values in the merged dataset\n",
    "print(\"Null values in merged dataset:\\n\", data.isnull().sum())\n",
    "\n",
    "# Drop any remaining rows with null values in essential columns\n",
    "data = data.dropna()\n",
    "\n",
    "# Confirm null values have been removed\n",
    "print(\"Null values after final drop:\\n\", data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109619\n"
     ]
    }
   ],
   "source": [
    "# after dropping null values\n",
    "cleaned_data = data.shape[0]\n",
    "print(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578\n"
     ]
    }
   ],
   "source": [
    "# number of dropped rows after cleaning\n",
    "rows_dropped = original_data - cleaned_data\n",
    "print(rows_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 109619 entries, 0 to 110196\n",
      "Data columns (total 29 columns):\n",
      " #   Column                                Non-Null Count   Dtype         \n",
      "---  ------                                --------------   -----         \n",
      " 0   order_id                              109619 non-null  object        \n",
      " 1   customer_id                           109619 non-null  object        \n",
      " 2   order_status                          109619 non-null  object        \n",
      " 3   order_purchase_timestamp              109619 non-null  datetime64[ns]\n",
      " 4   order_approved_at                     109619 non-null  datetime64[ns]\n",
      " 5   order_delivered_carrier_date          109619 non-null  datetime64[ns]\n",
      " 6   order_delivered_customer_date         109619 non-null  datetime64[ns]\n",
      " 7   order_estimated_delivery_date         109619 non-null  datetime64[ns]\n",
      " 8   delay                                 109619 non-null  int32         \n",
      " 9   order_item_id                         109619 non-null  int64         \n",
      " 10  product_id                            109619 non-null  object        \n",
      " 11  seller_id                             109619 non-null  object        \n",
      " 12  shipping_limit_date                   109619 non-null  datetime64[ns]\n",
      " 13  customer_zip_code_prefix              109619 non-null  int64         \n",
      " 14  seller_zip_code_prefix                109619 non-null  int64         \n",
      " 15  geolocation_zip_code_prefix_customer  109619 non-null  float64       \n",
      " 16  geolocation_lat_customer              109619 non-null  float64       \n",
      " 17  geolocation_lng_customer              109619 non-null  float64       \n",
      " 18  geolocation_city_customer             109619 non-null  object        \n",
      " 19  geolocation_state_customer            109619 non-null  object        \n",
      " 20  geolocation_zip_code_prefix_seller    109619 non-null  float64       \n",
      " 21  geolocation_lat_seller                109619 non-null  float64       \n",
      " 22  geolocation_lng_seller                109619 non-null  float64       \n",
      " 23  geolocation_city_seller               109619 non-null  object        \n",
      " 24  geolocation_state_seller              109619 non-null  object        \n",
      " 25  product_weight_g                      109619 non-null  float64       \n",
      " 26  product_length_cm                     109619 non-null  float64       \n",
      " 27  product_height_cm                     109619 non-null  float64       \n",
      " 28  product_width_cm                      109619 non-null  float64       \n",
      "dtypes: datetime64[ns](6), float64(10), int32(1), int64(3), object(9)\n",
      "memory usage: 24.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "-GOvburjN7WD"
   },
   "outputs": [],
   "source": [
    "data.to_csv(\"cleaned_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
